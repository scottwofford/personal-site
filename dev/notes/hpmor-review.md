# HPMOR Review - Placement Options

## Recommendation: B or D
It's substantial enough for a blog post and connects multiple themes (rationalism, AI alignment, your ethical stance). Could be titled something like "What HPMOR Taught Me About My Own Ethics."

## Options

| Option | Where | Pros | Cons |
|--------|-------|------|------|
| **A** | Reading section (new page) | Fits with book content, discoverable | Adds maintenance |
| **B** | Blog post | More visible, can share on social | Might feel thin for a standalone post |
| **C** | Philosophy section | Reinforces your ethical framework | Book review feels slightly off-topic there |
| **D** | Both: short excerpt on reading + full on blog | Best of both worlds | More work |

## Raw Content (from Goodreads)

```html
<a href="https://www.goodreads.com/book/show/10016013-harry-potter-and-the-methods-of-rationality" style="float: left; padding-right: 20px"><img border="0" alt="Harry Potter and the Methods of Rationality" src="https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1659761696l/10016013._SX98_.jpg" /></a><a href="https://www.goodreads.com/book/show/10016013-harry-potter-and-the-methods-of-rationality">Harry Potter and the Methods of Rationality</a> by <a href="https://www.goodreads.com/author/show/4533716.Eliezer_Yudkowsky">Eliezer Yudkowsky</a><br/>
My rating: <a href="https://www.goodreads.com/review/show/7400320784">5 of 5 stars</a><br /><br />
The characters in HPMOR represent different ethical stances. Understanding where I fit clarifies my own position.<br /><br /><b>I'm Not Quirrell</b><br /><br />Quirrell is a pure consequentialist with no constraints. His Azkaban argument is locally valid, but he makes it instrumentally—to recruit Harry—not because he cares about prisoner wee. A sufficiently intelligent optimizer can generate correct-seeming arguments for almost any conclusion. Quirrell's object-level points pass the smell test. His revealed preferences don't. That gap is the core problem in AI alignment.<br /><br />I share his impatience with systems that don't optimize. But I have lines he doesn't. He'd call them sentimentality. I call them load-bearing.<br /><br /><b>I'm Not Harry</b><br /><br />Harry treats ethics as an engineering problem. The Draco project—deprogramming a child through strategic deception—has good goals and Quirrell-coded methods.<br /><br />Hermione's objection: "you're not supposed to manipulate people, even toward true beliefs." I've updated toward her position. The Draco project treats people as optimization targets. The alternative is giving people tools to specify their own constraints, rather than imposing "correct" behavior from above.<br /><br /><b>I'm Closer to Hermione</b><br /><br />Hermione has deontological constraints Harry and Quirrele as weakness. But her felt sense that something is wrong with Harry's methods—before she can articulate it—is tracking something real.<br /><br />I relate to this. My discomfort with lying isn't derived from expected value calculations—it's a constraint I notice I have. The framework I've articulated is partly descriptive: explaining what I already do, not deriving it from scratch. The Wittgensteinian move: some things are shown, not said.<br />
<br/><br/>
<a href="https://www.goodreads.com/review/list/21741061-scott-wofford">View all my reviews</a>
```

## Clean Markdown Version

**Harry Potter and the Methods of Rationality** by Eliezer Yudkowsky
*My rating: 5 of 5 stars*

The characters in HPMOR represent different ethical stances. Understanding where I fit clarifies my own position.

### I'm Not Quirrell

Quirrell is a pure consequentialist with no constraints. His Azkaban argument is locally valid, but he makes it instrumentally—to recruit Harry—not because he cares about prisoner welfare. A sufficiently intelligent optimizer can generate correct-seeming arguments for almost any conclusion. Quirrell's object-level points pass the smell test. His revealed preferences don't. That gap is the core problem in AI alignment.

I share his impatience with systems that don't optimize. But I have lines he doesn't. He'd call them sentimentality. I call them load-bearing.

### I'm Not Harry

Harry treats ethics as an engineering problem. The Draco project—deprogramming a child through strategic deception—has good goals and Quirrell-coded methods.

Hermione's objection: "you're not supposed to manipulate people, even toward true beliefs." I've updated toward her position. The Draco project treats people as optimization targets. The alternative is giving people tools to specify their own constraints, rather than imposing "correct" behavior from above.

### I'm Closer to Hermione

Hermione has deontological constraints Harry and Quirrell dismiss as weakness. But her felt sense that something is wrong with Harry's methods—before she can articulate it—is tracking something real.

I relate to this. My discomfort with lying isn't derived from expected value calculations—it's a constraint I notice I have. The framework I've articulated is partly descriptive: explaining what I already do, not deriving it from scratch. The Wittgensteinian move: some things are shown, not said.

---
*[View all my reviews](https://www.goodreads.com/review/list/21741061-scott-wofford)*
