<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Wikipedia: Somebody is wrong on the internet - Scott Wofford</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/styles.css">
  <style>
    .meme-container {
      text-align: center;
      margin: 1.5rem 0;
    }
    .meme-container img {
      max-width: 100%;
      border-radius: 4px;
    }
    .meme-caption {
      font-size: 0.85rem;
      color: #666;
      margin-top: 0.5rem;
    }
  </style>
</head>
<body>
  <div class="section-nav">
    <a href="/">← home</a> / <a href="/philosophy/" class="section-name">philosophy & epistemics</a>
    <div class="siblings">
      <a href="/philosophy/personal-philosophy.html">Philosophy</a>
      <a href="/philosophy/x-wrong-on-internet.html">X</a>
      <a href="/philosophy/wikipedia-wrong-on-internet.html" class="current">Wikipedia</a>
    </div>
  </div>

  <h1>Wikipedia: Somebody is wrong on the internet</h1>
  <p class="subtitle">Contributing to humanity's knowledge base.</p>

  <hr>

  <div class="meme-container">
    <img src="https://imgs.xkcd.com/comics/duty_calls.png" alt="xkcd 386: Duty Calls - 'I can't go to bed yet, someone is WRONG on the internet'">
    <p class="meme-caption">xkcd #386: "Duty Calls" — <a href="https://xkcd.com/386/">source</a></p>
  </div>

  <hr>

  <h2>Why I Do This</h2>
  <p>There's something deeply satisfying about fixing wrong information where people actually look for answers. Wikipedia is read by billions. Community Notes reach millions on X. When I see something incorrect—especially on topics I know well—I feel a pull to fix it.</p>

  <p>This isn't about being right. It's about the information ecosystem being better. Every corrected article, every helpful Community Note, is a small improvement to the shared knowledge base we all rely on.</p>

  <hr>

  <h2>Wikipedia Editing</h2>
  <p>I've been editing Wikipedia since college. It started with fixing small errors on topics I cared about and evolved into more substantial contributions. The process is meditative: find a claim, verify it, improve it, cite it properly.</p>

  <p>What I love about Wikipedia:</p>
  <ul>
    <li><strong>Permanence.</strong> Edits persist. A fix I make today helps readers for years.</li>
    <li><strong>Neutrality norms.</strong> The community enforces balanced coverage, even on contentious topics.</li>
    <li><strong>Verification culture.</strong> Claims need sources. This is how epistemics should work.</li>
  </ul>

  <hr>

  <h2>Community Notes</h2>
  <p>X's Community Notes (formerly Birdwatch) is one of the most interesting experiments in crowdsourced fact-checking. The bridging algorithm—which requires agreement across ideological lines—produces notes that feel genuinely helpful rather than partisan.</p>

  <p>I contribute because:</p>
  <ul>
    <li>Misinformation spreads fast; good context needs to catch up</li>
    <li>The bridging model rewards accuracy over ideology</li>
    <li>It's satisfying to see a note I contributed appear under a viral post</li>
  </ul>

  <hr>

  <h2>Automating "Somebody is Wrong"</h2>
  <p>Here's the thing: this doesn't scale. One person can only fix so many errors. The internet generates wrong information faster than humans can correct it.</p>

  <p>This is part of why I'm working on <a href="https://luthienresearch.org">Luthien</a>. AI agents are increasingly writing content, making claims, taking actions. The question isn't whether AI will shape information—it's whether we can verify that AI-generated content meets standards for accuracy and honesty.</p>

  <p>What if we could:</p>
  <ul>
    <li>Automatically flag claims that need verification?</li>
    <li>Surface discrepancies between what an AI says and what it does?</li>
    <li>Help humans review AI outputs more efficiently?</li>
  </ul>

  <p>The same instinct that makes me edit Wikipedia at midnight—<em>someone is wrong on the internet and I must fix it</em>—now drives my work on AI control. The scale is different. The impulse is the same.</p>

  <hr>

  <p><em>"I can't go to bed yet. Someone is wrong on the internet."</em></p>

</body>
</html>
